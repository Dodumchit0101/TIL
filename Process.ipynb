{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Process.ipynb","provenance":[],"collapsed_sections":["eOAr5zegj0mE","YKhMsyohj0mL"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8my5nhfUj0lv"},"source":["# Tensorflow Object Detection API\n","- Tensorflow Object Detection API는 TensorFlow를 이용해서 Object Detection 모델을 train하고 deploy하는 것을 쉽게 도와주는 오픈소스 프레임워크.\n","- https://github.com/tensorflow/models/tree/master/research/object_detection\n","- Tutorial: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/"]},{"cell_type":"markdown","metadata":{"id":"oqu4WaMaj0l5"},"source":["# Custom (Image) Data 구하기"]},{"cell_type":"markdown","metadata":{"id":"WE4oL42Aj0l6"},"source":["# Custom (Image) Data Labeling"]},{"cell_type":"markdown","metadata":{"id":"jA66YKW3j0l6"},"source":["# 전단계\n","- 구글드라이브 연결\n","- 상대경로로 할 것이므로 Process.ipynb 있는 디렉토리로 이동\n","- workspace/images 에 이미지 데이터셋 넣고 압축 푼다. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7H7sQn_1j0l7","executionInfo":{"status":"ok","timestamp":1620998862859,"user_tz":-540,"elapsed":18881,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"47419e4e-512e-4bfd-a77a-deea47052b07"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dU2pZwcQj0l8","executionInfo":{"status":"ok","timestamp":1620991595560,"user_tz":-540,"elapsed":24447,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"1cb05c5a-ee38-48ef-e457-47344b2fae1e"},"source":["%cd /content/drive/MyDrive/object_detection/object_detection_workspace"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/object_detection/object_detection_workspace\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"as9rzlWsldOI","executionInfo":{"status":"ok","timestamp":1620991595562,"user_tz":-540,"elapsed":24432,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"97e25e07-2049-4288-f308-ff22cbb44461"},"source":["%pwd"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/object_detection/object_detection_workspace'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZ4jnQSBldoN","executionInfo":{"status":"ok","timestamp":1620993424404,"user_tz":-540,"elapsed":1853261,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"5ed1539c-146e-40cc-a27c-e069d0f28a31"},"source":["# 이미지, annotation 파일들을 workspace/images 디렉토리로 이동\n","# 압축 풀기\n","!unzip hand_images.zip  -d /content/drive/MyDrive/object_detection/object_detection_workspace/workspace/images"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  hand_images.zip\n","replace /content/drive/MyDrive/object_detection/object_detection_workspace/workspace/images/five-9c78625a-b163-11eb-923c-e82a44a8139a.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VOHZWnNClloI","executionInfo":{"status":"ok","timestamp":1620993424413,"user_tz":-540,"elapsed":1853268,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"lS2D2DO1llwr","executionInfo":{"status":"ok","timestamp":1620993424416,"user_tz":-540,"elapsed":1853268,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mX_HKLaOj0l9"},"source":["# Tensorflow Object Detection 2 API 설치\n","1. clone \n","    - `!git clone https://github.com/tensorflow/models.git`\n","1. PYTHONPATH 환경설정에 models/research 추가  \n","1. 필요 모듈 설치\n","    - `!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk`\n","    - `!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools`\n","1. proto 파일 컴파일\n","    - models/research 경로로 이동\n","        - `%cd models/research`\n","    - `!protoc object_detection/protos/*.proto --python_out=.`\n","1. setup.py 를 이용해 필요한 모듈 추가 설치\n","    - setup.py를 현재 디렉토리로 카피\n","        - `!cp object_detection/packages/tf2/setup.py . `\n","    - 설치\n","        - `!python -m pip install . `\n","    - 설치 확인 - 아래 스크립트 실행시 오류 없이 실행되면 설치 잘 된 것임.\n","        - `!python object_detection/builders/model_builder_tf2_test.py`\n","1. 원래 디렉토리로 이동\n","    - `%cd ../..`        "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"JknKqj1Mj0l-","executionInfo":{"status":"ok","timestamp":1620993424420,"user_tz":-540,"elapsed":1853258,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"09639222-880f-4d88-8234-c751a4e685c0"},"source":["%pwd"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/object_detection/object_detection_workspace'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hC3utIOuj0l-","executionInfo":{"status":"ok","timestamp":1620993424422,"user_tz":-540,"elapsed":1853246,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"41339232-3f95-4957-d0ff-cdcaa21793a7"},"source":["!git clone https://github.com/tensorflow/models.git"],"execution_count":6,"outputs":[{"output_type":"stream","text":["fatal: destination path 'models' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uwSkSuDBj0l_","executionInfo":{"status":"ok","timestamp":1620993424425,"user_tz":-540,"elapsed":1853239,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# 2. PYTHONPATH 환경설정. models/research 경로\n","import os\n","os.environ['PYTHONPATH'] += ':/content/drive/MyDrive/object_detection/object_detection_workspace/models/research'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"e90GNrcCj0l_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620993436038,"user_tz":-540,"elapsed":1864842,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"288f5931-de2b-40bc-e81f-166eb85d2a5e"},"source":["# 필요 모듈/프로그램 설치\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package python-bs4.\n","(Reading database ... 160706 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.5_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DwBG7RtSj0l_","executionInfo":{"status":"ok","timestamp":1620993439826,"user_tz":-540,"elapsed":1868620,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnBNT-K1j0l_","executionInfo":{"status":"ok","timestamp":1620993439830,"user_tz":-540,"elapsed":1868615,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"47bc0aa3-3023-440d-8052-8b98a73c5408"},"source":["# 4. proto 파일들 컴파일\n","%cd models/research/"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/object_detection/object_detection_workspace/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DYJwhnxej0mA","executionInfo":{"status":"ok","timestamp":1620993467746,"user_tz":-540,"elapsed":1896518,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLktF56auUJK","executionInfo":{"status":"ok","timestamp":1620993468687,"user_tz":-540,"elapsed":1897450,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# setup.py 실행해서 TFOD API를 설치\n","!cp object_detection/packages/tf2/setup.py ."],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjcdnKzMuUMw","executionInfo":{"status":"ok","timestamp":1620994124169,"user_tz":-540,"elapsed":2552915,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"16ec3b55-13d3-45e4-8222-09d4316b3875"},"source":["!python -m pip install ."],"execution_count":13,"outputs":[{"output_type":"stream","text":["Processing /content/drive/MyDrive/object_detection/object_detection_workspace/models/research\n","Collecting avro-python3\n","  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n","Collecting apache-beam\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/7f/342e6bf4bbdc55418c929b3281948070ef4ca83e198dc9135352c25799f9/apache_beam-2.29.0-cp37-cp37m-manylinux2010_x86_64.whl (9.6MB)\n","\u001b[K     |████████████████████████████████| 9.6MB 12.6MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 33.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 31.0MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n","Collecting dill<0.3.2,>=0.3.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n","\u001b[K     |████████████████████████████████| 153kB 44.1MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting fastavro<2,>=0.21.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/26/cc1acc339eb1b8423c32b0a1dca524214012e577c22ce8fdd58d5213f9b4/fastavro-1.4.0-cp37-cp37m-manylinux2014_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 32.2MB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n","Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n","Collecting requests<3.0.0,>=2.24.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n","Collecting future<1.0.0,>=0.18.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 29.2MB/s \n","\u001b[?25hRequirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (56.1.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Collecting tensorflow-model-optimization>=0.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n","\u001b[K     |████████████████████████████████| 174kB 37.9MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n","Collecting dataclasses\n","  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n","Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.4.1)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n","Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n","\u001b[K     |████████████████████████████████| 706kB 29.3MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 28.4MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n","Collecting py-cpuinfo>=3.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n","\u001b[K     |████████████████████████████████| 102kB 11.2MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/84/72ec52fbac4775c2a5bf0ee5573c922a0cac35eb841907edf56493a5e313/opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n","\u001b[K     |████████████████████████████████| 38.2MB 76kB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 30.7MB/s \n","\u001b[?25hCollecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.1)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.30.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Building wheels for collected packages: object-detection, avro-python3, dill, future, py-cpuinfo, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1648944 sha256=7153bdcb4f78c78f45866309a5983f2f195b0f969077fa88b0ef36052f515db1\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3ibonha9/wheels/7e/ab/15/b21a44d49c21930ccb95c073ce8b06f2d493604fe4e2e04237\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=cf811e86da16d9d4328882515e11fcdd25438d1934205f18000adc656fd5f3ca\n","  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=cfcef2f989e4aaa2af6b46b71ae68bb13fa45448e9a9ab1f5c301651f1d8ab2e\n","  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=dbc8071399d28cefffff632cbf4b104fcce1599d6d18426cf2ea7b7ed1f8b578\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=12d660332ea3e5fdac6b9e3e8e1d0f689aa434947919579c9ee63b715c67d1ed\n","  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=e6e5a8ba83b0085ec2127a2400bc76d9852f2bf8080f2717ac14601868a0a7fc\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built object-detection avro-python3 dill future py-cpuinfo seqeval\n","\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: apache-beam 2.29.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n","Installing collected packages: avro-python3, dill, fastavro, requests, hdfs, future, apache-beam, tf-slim, lvis, tensorflow-model-optimization, dataclasses, tensorflow-addons, pyyaml, py-cpuinfo, opencv-python-headless, sentencepiece, seqeval, tf-models-official, object-detection\n","  Found existing installation: dill 0.3.3\n","    Uninstalling dill-0.3.3:\n","      Successfully uninstalled dill-0.3.3\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed apache-beam-2.29.0 avro-python3-1.10.2 dataclasses-0.6 dill-0.3.1.1 fastavro-1.4.0 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.12.1 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0 tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j_rprBMMu9R2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620994170460,"user_tz":-540,"elapsed":2599190,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"fc026bff-1a52-47a1-b107-6c6f276963bc"},"source":["!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2021-05-14 12:08:43.606538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Running tests under Python 3.7.10: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2021-05-14 12:08:48.398257: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-05-14 12:08:48.399572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-05-14 12:08:48.483269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:48.484211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n","coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n","2021-05-14 12:08:48.484283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:08:48.621798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-05-14 12:08:48.621918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-05-14 12:08:48.781341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-05-14 12:08:48.803967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-05-14 12:08:49.078487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-05-14 12:08:49.098118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-05-14 12:08:49.103702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-05-14 12:08:49.103879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:49.104816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:49.109301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-05-14 12:08:49.109907: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-05-14 12:08:49.110040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:49.110832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n","coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n","2021-05-14 12:08:49.110874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:08:49.110946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-05-14 12:08:49.110986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-05-14 12:08:49.111027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-05-14 12:08:49.111077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-05-14 12:08:49.111119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-05-14 12:08:49.111182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-05-14 12:08:49.111222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-05-14 12:08:49.111321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:49.112261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:49.113072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-05-14 12:08:49.116921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:08:53.486666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-05-14 12:08:53.486768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-05-14 12:08:53.486805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-05-14 12:08:53.495243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:53.496102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:53.496959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:08:53.497724: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-05-14 12:08:53.497786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10637 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","W0514 12:08:53.950938 139794276198272 model_builder.py:1061] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 6.13s\n","I0514 12:08:54.504648 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 6.13s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.06s\n","I0514 12:08:55.566536 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.06s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.46s\n","I0514 12:08:56.026344 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.46s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n","I0514 12:08:56.462059 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","W0514 12:08:56.464807 139794276198272 mobilenet_v2.py:286] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.82s\n","I0514 12:08:59.281259 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.82s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0514 12:08:59.282536 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0514 12:08:59.315733 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n","I0514 12:08:59.350502 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n","I0514 12:08:59.378660 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.17s\n","I0514 12:08:59.552515 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n","I0514 12:08:59.723535 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.17s\n","I0514 12:08:59.896847 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.18s\n","I0514 12:09:00.082362 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.18s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n","I0514 12:09:00.263317 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n","I0514 12:09:00.317174 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0514 12:09:00.667473 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0514 12:09:00.667733 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0514 12:09:00.667867 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0514 12:09:00.674631 139794276198272 efficientnet_model.py:147] round_filter input=32 output=32\n","I0514 12:09:00.828943 139794276198272 efficientnet_model.py:147] round_filter input=32 output=32\n","I0514 12:09:00.829168 139794276198272 efficientnet_model.py:147] round_filter input=16 output=16\n","I0514 12:09:00.901280 139794276198272 efficientnet_model.py:147] round_filter input=16 output=16\n","I0514 12:09:00.901461 139794276198272 efficientnet_model.py:147] round_filter input=24 output=24\n","I0514 12:09:01.096122 139794276198272 efficientnet_model.py:147] round_filter input=24 output=24\n","I0514 12:09:01.096349 139794276198272 efficientnet_model.py:147] round_filter input=40 output=40\n","I0514 12:09:01.280735 139794276198272 efficientnet_model.py:147] round_filter input=40 output=40\n","I0514 12:09:01.280940 139794276198272 efficientnet_model.py:147] round_filter input=80 output=80\n","I0514 12:09:01.599914 139794276198272 efficientnet_model.py:147] round_filter input=80 output=80\n","I0514 12:09:01.600158 139794276198272 efficientnet_model.py:147] round_filter input=112 output=112\n","I0514 12:09:01.892777 139794276198272 efficientnet_model.py:147] round_filter input=112 output=112\n","I0514 12:09:01.892992 139794276198272 efficientnet_model.py:147] round_filter input=192 output=192\n","I0514 12:09:02.285240 139794276198272 efficientnet_model.py:147] round_filter input=192 output=192\n","I0514 12:09:02.285446 139794276198272 efficientnet_model.py:147] round_filter input=320 output=320\n","I0514 12:09:02.385921 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0514 12:09:02.430877 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:02.516597 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0514 12:09:02.516814 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0514 12:09:02.516923 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0514 12:09:02.521864 139794276198272 efficientnet_model.py:147] round_filter input=32 output=32\n","I0514 12:09:02.541204 139794276198272 efficientnet_model.py:147] round_filter input=32 output=32\n","I0514 12:09:02.541338 139794276198272 efficientnet_model.py:147] round_filter input=16 output=16\n","I0514 12:09:02.706748 139794276198272 efficientnet_model.py:147] round_filter input=16 output=16\n","I0514 12:09:02.706977 139794276198272 efficientnet_model.py:147] round_filter input=24 output=24\n","I0514 12:09:02.991079 139794276198272 efficientnet_model.py:147] round_filter input=24 output=24\n","I0514 12:09:02.991331 139794276198272 efficientnet_model.py:147] round_filter input=40 output=40\n","I0514 12:09:03.275178 139794276198272 efficientnet_model.py:147] round_filter input=40 output=40\n","I0514 12:09:03.275405 139794276198272 efficientnet_model.py:147] round_filter input=80 output=80\n","I0514 12:09:03.690672 139794276198272 efficientnet_model.py:147] round_filter input=80 output=80\n","I0514 12:09:03.690873 139794276198272 efficientnet_model.py:147] round_filter input=112 output=112\n","I0514 12:09:04.066037 139794276198272 efficientnet_model.py:147] round_filter input=112 output=112\n","I0514 12:09:04.066295 139794276198272 efficientnet_model.py:147] round_filter input=192 output=192\n","I0514 12:09:04.565328 139794276198272 efficientnet_model.py:147] round_filter input=192 output=192\n","I0514 12:09:04.565526 139794276198272 efficientnet_model.py:147] round_filter input=320 output=320\n","I0514 12:09:04.752132 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0514 12:09:04.786467 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:04.882480 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0514 12:09:04.882672 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0514 12:09:04.882777 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0514 12:09:04.887613 139794276198272 efficientnet_model.py:147] round_filter input=32 output=32\n","I0514 12:09:04.906852 139794276198272 efficientnet_model.py:147] round_filter input=32 output=32\n","I0514 12:09:04.907019 139794276198272 efficientnet_model.py:147] round_filter input=16 output=16\n","I0514 12:09:05.216721 139794276198272 efficientnet_model.py:147] round_filter input=16 output=16\n","I0514 12:09:05.216922 139794276198272 efficientnet_model.py:147] round_filter input=24 output=24\n","I0514 12:09:05.516376 139794276198272 efficientnet_model.py:147] round_filter input=24 output=24\n","I0514 12:09:05.516581 139794276198272 efficientnet_model.py:147] round_filter input=40 output=48\n","I0514 12:09:05.796542 139794276198272 efficientnet_model.py:147] round_filter input=40 output=48\n","I0514 12:09:05.796750 139794276198272 efficientnet_model.py:147] round_filter input=80 output=88\n","I0514 12:09:06.176482 139794276198272 efficientnet_model.py:147] round_filter input=80 output=88\n","I0514 12:09:06.176729 139794276198272 efficientnet_model.py:147] round_filter input=112 output=120\n","I0514 12:09:06.584844 139794276198272 efficientnet_model.py:147] round_filter input=112 output=120\n","I0514 12:09:06.585063 139794276198272 efficientnet_model.py:147] round_filter input=192 output=208\n","I0514 12:09:07.064002 139794276198272 efficientnet_model.py:147] round_filter input=192 output=208\n","I0514 12:09:07.064234 139794276198272 efficientnet_model.py:147] round_filter input=320 output=352\n","I0514 12:09:07.246161 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0514 12:09:07.279310 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:07.386295 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0514 12:09:07.386522 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0514 12:09:07.386624 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0514 12:09:07.392704 139794276198272 efficientnet_model.py:147] round_filter input=32 output=40\n","I0514 12:09:07.412774 139794276198272 efficientnet_model.py:147] round_filter input=32 output=40\n","I0514 12:09:07.412947 139794276198272 efficientnet_model.py:147] round_filter input=16 output=24\n","I0514 12:09:07.570226 139794276198272 efficientnet_model.py:147] round_filter input=16 output=24\n","I0514 12:09:07.570424 139794276198272 efficientnet_model.py:147] round_filter input=24 output=32\n","I0514 12:09:07.857746 139794276198272 efficientnet_model.py:147] round_filter input=24 output=32\n","I0514 12:09:07.857957 139794276198272 efficientnet_model.py:147] round_filter input=40 output=48\n","I0514 12:09:08.144028 139794276198272 efficientnet_model.py:147] round_filter input=40 output=48\n","I0514 12:09:08.144245 139794276198272 efficientnet_model.py:147] round_filter input=80 output=96\n","I0514 12:09:08.655978 139794276198272 efficientnet_model.py:147] round_filter input=80 output=96\n","I0514 12:09:08.656204 139794276198272 efficientnet_model.py:147] round_filter input=112 output=136\n","I0514 12:09:09.140624 139794276198272 efficientnet_model.py:147] round_filter input=112 output=136\n","I0514 12:09:09.140834 139794276198272 efficientnet_model.py:147] round_filter input=192 output=232\n","I0514 12:09:09.740822 139794276198272 efficientnet_model.py:147] round_filter input=192 output=232\n","I0514 12:09:09.741028 139794276198272 efficientnet_model.py:147] round_filter input=320 output=384\n","I0514 12:09:09.926559 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0514 12:09:09.963325 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:10.254952 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0514 12:09:10.255179 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0514 12:09:10.255285 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0514 12:09:10.260261 139794276198272 efficientnet_model.py:147] round_filter input=32 output=48\n","I0514 12:09:10.279568 139794276198272 efficientnet_model.py:147] round_filter input=32 output=48\n","I0514 12:09:10.279707 139794276198272 efficientnet_model.py:147] round_filter input=16 output=24\n","I0514 12:09:10.446628 139794276198272 efficientnet_model.py:147] round_filter input=16 output=24\n","I0514 12:09:10.446846 139794276198272 efficientnet_model.py:147] round_filter input=24 output=32\n","I0514 12:09:10.836101 139794276198272 efficientnet_model.py:147] round_filter input=24 output=32\n","I0514 12:09:10.836340 139794276198272 efficientnet_model.py:147] round_filter input=40 output=56\n","I0514 12:09:11.227068 139794276198272 efficientnet_model.py:147] round_filter input=40 output=56\n","I0514 12:09:11.227318 139794276198272 efficientnet_model.py:147] round_filter input=80 output=112\n","I0514 12:09:11.833884 139794276198272 efficientnet_model.py:147] round_filter input=80 output=112\n","I0514 12:09:11.834104 139794276198272 efficientnet_model.py:147] round_filter input=112 output=160\n","I0514 12:09:12.418714 139794276198272 efficientnet_model.py:147] round_filter input=112 output=160\n","I0514 12:09:12.418937 139794276198272 efficientnet_model.py:147] round_filter input=192 output=272\n","I0514 12:09:13.182482 139794276198272 efficientnet_model.py:147] round_filter input=192 output=272\n","I0514 12:09:13.182691 139794276198272 efficientnet_model.py:147] round_filter input=320 output=448\n","I0514 12:09:13.370724 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0514 12:09:13.405325 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:13.537524 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0514 12:09:13.537828 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0514 12:09:13.537951 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0514 12:09:13.544730 139794276198272 efficientnet_model.py:147] round_filter input=32 output=48\n","I0514 12:09:13.566351 139794276198272 efficientnet_model.py:147] round_filter input=32 output=48\n","I0514 12:09:13.566571 139794276198272 efficientnet_model.py:147] round_filter input=16 output=24\n","I0514 12:09:13.820333 139794276198272 efficientnet_model.py:147] round_filter input=16 output=24\n","I0514 12:09:13.820548 139794276198272 efficientnet_model.py:147] round_filter input=24 output=40\n","I0514 12:09:14.304774 139794276198272 efficientnet_model.py:147] round_filter input=24 output=40\n","I0514 12:09:14.304995 139794276198272 efficientnet_model.py:147] round_filter input=40 output=64\n","I0514 12:09:14.803757 139794276198272 efficientnet_model.py:147] round_filter input=40 output=64\n","I0514 12:09:14.803979 139794276198272 efficientnet_model.py:147] round_filter input=80 output=128\n","I0514 12:09:15.486556 139794276198272 efficientnet_model.py:147] round_filter input=80 output=128\n","I0514 12:09:15.486762 139794276198272 efficientnet_model.py:147] round_filter input=112 output=176\n","I0514 12:09:16.408026 139794276198272 efficientnet_model.py:147] round_filter input=112 output=176\n","I0514 12:09:16.408240 139794276198272 efficientnet_model.py:147] round_filter input=192 output=304\n","I0514 12:09:17.296062 139794276198272 efficientnet_model.py:147] round_filter input=192 output=304\n","I0514 12:09:17.296326 139794276198272 efficientnet_model.py:147] round_filter input=320 output=512\n","I0514 12:09:17.582721 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0514 12:09:17.621021 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:17.759344 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0514 12:09:17.759612 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0514 12:09:17.759747 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0514 12:09:17.765101 139794276198272 efficientnet_model.py:147] round_filter input=32 output=56\n","I0514 12:09:17.785895 139794276198272 efficientnet_model.py:147] round_filter input=32 output=56\n","I0514 12:09:17.786068 139794276198272 efficientnet_model.py:147] round_filter input=16 output=32\n","I0514 12:09:18.021755 139794276198272 efficientnet_model.py:147] round_filter input=16 output=32\n","I0514 12:09:18.021994 139794276198272 efficientnet_model.py:147] round_filter input=24 output=40\n","I0514 12:09:18.611543 139794276198272 efficientnet_model.py:147] round_filter input=24 output=40\n","I0514 12:09:18.611792 139794276198272 efficientnet_model.py:147] round_filter input=40 output=72\n","I0514 12:09:19.201608 139794276198272 efficientnet_model.py:147] round_filter input=40 output=72\n","I0514 12:09:19.201840 139794276198272 efficientnet_model.py:147] round_filter input=80 output=144\n","I0514 12:09:20.023576 139794276198272 efficientnet_model.py:147] round_filter input=80 output=144\n","I0514 12:09:20.023783 139794276198272 efficientnet_model.py:147] round_filter input=112 output=200\n","I0514 12:09:20.817289 139794276198272 efficientnet_model.py:147] round_filter input=112 output=200\n","I0514 12:09:20.817510 139794276198272 efficientnet_model.py:147] round_filter input=192 output=344\n","I0514 12:09:22.138561 139794276198272 efficientnet_model.py:147] round_filter input=192 output=344\n","I0514 12:09:22.138791 139794276198272 efficientnet_model.py:147] round_filter input=320 output=576\n","I0514 12:09:22.426375 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0514 12:09:22.466311 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 12:09:22.611062 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0514 12:09:22.611299 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0514 12:09:22.611403 139794276198272 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0514 12:09:22.616509 139794276198272 efficientnet_model.py:147] round_filter input=32 output=64\n","I0514 12:09:22.636138 139794276198272 efficientnet_model.py:147] round_filter input=32 output=64\n","I0514 12:09:22.636284 139794276198272 efficientnet_model.py:147] round_filter input=16 output=32\n","I0514 12:09:22.964620 139794276198272 efficientnet_model.py:147] round_filter input=16 output=32\n","I0514 12:09:22.964860 139794276198272 efficientnet_model.py:147] round_filter input=24 output=48\n","I0514 12:09:23.659379 139794276198272 efficientnet_model.py:147] round_filter input=24 output=48\n","I0514 12:09:23.659643 139794276198272 efficientnet_model.py:147] round_filter input=40 output=80\n","I0514 12:09:24.339983 139794276198272 efficientnet_model.py:147] round_filter input=40 output=80\n","I0514 12:09:24.340200 139794276198272 efficientnet_model.py:147] round_filter input=80 output=160\n","I0514 12:09:25.316538 139794276198272 efficientnet_model.py:147] round_filter input=80 output=160\n","I0514 12:09:25.316758 139794276198272 efficientnet_model.py:147] round_filter input=112 output=224\n","I0514 12:09:26.283755 139794276198272 efficientnet_model.py:147] round_filter input=112 output=224\n","I0514 12:09:26.283960 139794276198272 efficientnet_model.py:147] round_filter input=192 output=384\n","I0514 12:09:27.533926 139794276198272 efficientnet_model.py:147] round_filter input=192 output=384\n","I0514 12:09:27.534150 139794276198272 efficientnet_model.py:147] round_filter input=320 output=640\n","I0514 12:09:28.189028 139794276198272 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0514 12:09:28.224349 139794276198272 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.07s\n","I0514 12:09:28.385004 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.07s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0514 12:09:28.393394 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0514 12:09:28.395480 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0514 12:09:28.396110 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0514 12:09:28.398119 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0514 12:09:28.400006 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0514 12:09:28.400638 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0514 12:09:28.401895 139794276198272 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 40.025s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AxS1qYDEu-ZP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620994170462,"user_tz":-540,"elapsed":2599175,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"c5a868a6-a248-4b70-f678-e78c6f47bab7"},"source":["# base 디렉토리로 이동\n","%cd ../.."],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/object_detection/object_detection_workspace\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"flDLahRbva6P","executionInfo":{"status":"ok","timestamp":1620994170464,"user_tz":-540,"elapsed":2599174,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ULxAc2D_uUQx","executionInfo":{"status":"ok","timestamp":1620994170465,"user_tz":-540,"elapsed":2599172,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"57NZKueij0mA"},"source":["# 경로 설정"]},{"cell_type":"code","metadata":{"id":"yPKxdD6Tj0mB","executionInfo":{"status":"ok","timestamp":1620994170466,"user_tz":-540,"elapsed":2599164,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["import os"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWjS5qMfj0mB","executionInfo":{"status":"ok","timestamp":1620994170466,"user_tz":-540,"elapsed":2599156,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["BASE_PATH = 'workspace' #작업 시 생기는 파일들을 저장할 root 디렉토리\n","SCRIPT_PATH = 'scripts'  #utility python script들이 저장된 디렉토리\n","TF_OD_API_PATH = 'models'  #Tendorflow object detection api 설치 경로\n","\n","IMAGE_PATH = os.path.join(BASE_PATH, \"images\")  #image data들, annotation 파일들이 저장된 디렉토리\n","LABEL_MAP_PATH = os.path.join(BASE_PATH, 'labelmap')  #Label map 파일이 저장된 디렉토리\n","LABEL_MAP_FILE_PATH = os.path.join(LABEL_MAP_PATH, 'label_map.pbtxt')  #label map 파일 경로\n","\n","TF_RECORD_PATH = os.path.join(BASE_PATH, 'tfrecord')  #TFRecord파일들을 저장할 경로\n","\n","MODEL_PATH = os.path.join(BASE_PATH, 'model')  #pretrained 모델, fine tuning한 모델, weight(chkpt), pipeline.config을 저장할 경로\n","CHECK_POINT_PATH = os.path.join(MODEL_PATH, 'checkpoint')  #학습 도중에 중간중간 저장되는 weight\n","EXPORT_MODEL_PATH = os.path.join(MODEL_PATH, 'export_model')  #fine tuning한 최종 모델을 저장할 경로\n","PIPELINE_CONFIG_PATH = os.path.join(MODEL_PATH, 'pipeline.config')  #pipeline.config(설정파일)의 경로\n","\n","PRE_TRAINED_MODEL_PATH = os.path.join(BASE_PATH, 'pre_trained_model')  #전이학습 시킬 모델을 저장할 경로\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"qd7BV2P1wzlE","executionInfo":{"status":"ok","timestamp":1620994170467,"user_tz":-540,"elapsed":2599153,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FfaFfJwAj0mB"},"source":["# Custom data 학습 시키기\n","\n","## 다음 세가지 작업이 필요\n","<span style='font-weight:bold;font-size:1.3em'>1. Label Map 파일 생성</span>\n","- 분류 하고자 하는 object의 class와 그 class id 를 pbtxt text 파일로 작성\n","- `models\\research\\object_detection\\data`\n","\n","```\n","item {\n","  id: 1\n","  name: 'aeroplane'\n","}\n","\n","item {\n","  id: 2\n","  name: 'bicycle'\n","}\n","...\n","```\n","\n","<span style='font-weight:bold;font-size:1.3em'>2. pipeline.config</span>\n","- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n","- `models\\research\\object_detection\\samples\\configs`\n","\n","<span style='font-weight:bold;font-size:1.3em'>3. 학습/검증/테스트에 사용할 데이터셋을 TFRecord 로 구성</span>\n","- 주요 데이터셋을 TFRecord로 생성하는 코드\n","- `models\\research\\object_detection\\dataset_tools`"]},{"cell_type":"markdown","metadata":{"id":"LEjOZKCEj0mB"},"source":["# 데이터셋 준비"]},{"cell_type":"code","metadata":{"id":"pi9l4b42j0mC","executionInfo":{"status":"ok","timestamp":1620994170468,"user_tz":-540,"elapsed":2599146,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# 디렉토리 만들기\n","train_dir = os.path.join(IMAGE_PATH, 'train')  #train 데이터 저장 경로\n","test_dir = os.path.join(IMAGE_PATH, 'test')\n","\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(test_dir, exist_ok=True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSnu4DXOaG-Z","executionInfo":{"status":"ok","timestamp":1620994170468,"user_tz":-540,"elapsed":2599134,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"6974f290-585b-4602-fb1e-ab96a7580b17"},"source":["# 카피\n","file_list = os.listdir(IMAGE_PATH)\n","# len(file_list)\n","# file_list[:10]\n","image_list = [fname for fname in file_list if os.path.splitext(fname)[-1]=='.jpg']  #확장자가 .jpg인 파일들을 조회\n","len(image_list)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["68"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"IEagRgRYaHBy","executionInfo":{"status":"ok","timestamp":1620994292406,"user_tz":-540,"elapsed":2721061,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# shutil.copy(원본 경로, 복사할 경로)\n","import shutil\n","\n","count = 0\n","current_label = None\n","train_len = 12\n","\n","for img_name in image_list:\n","    # print(img_name)\n","    label = img_name.split('-')[0]\n","    ann_name = os.path.splitext(img_name)[0]+'.xml'  #annotation 파일이름 조회\n","    # print(ann_name)\n","    if current_label != label:  #새로운 라벨에 대한 카피 시작\n","        count = 0\n","        current_label = label\n","\n","    # 복사작업\n","    img_path = os.path.join(IMAGE_PATH, img_name)\n","    ann_path = os.path.join(IMAGE_PATH, ann_name)\n","    train_path = os.path.join(IMAGE_PATH, 'train')  #카피 대상 디렉토리\n","    test_path = os.path.join(IMAGE_PATH, 'test')\n","\n","    # count가 train_len(12)보다 작으면 train 폴더에 카피, 이상이면 test 폴더에 카피\n","    if count < 12:\n","        shutil.copy(img_path, train_path)  #이미지 카피\n","        shutil.copy(ann_path, train_path)  #annotation 파일 카피\n","    else:\n","        shutil.copy(img_path, test_path)\n","        shutil.copy(ann_path, test_path)\n","    count += 1"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mIprOP3IbdJu","executionInfo":{"status":"ok","timestamp":1620994292407,"user_tz":-540,"elapsed":2721051,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"4c96ce32-82db-4638-cb9c-9cd11034f4be"},"source":["len(os.listdir('workspace/images/train'))"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["120"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"swMT4DW0j0mC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620994292408,"user_tz":-540,"elapsed":2721036,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"927481e3-1af6-4c55-e8d8-f87a86bc2f92"},"source":["len(os.listdir('workspace/images/test'))"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"lLoPZA9ikoE7","executionInfo":{"status":"ok","timestamp":1620994292408,"user_tz":-540,"elapsed":2721032,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywbaMWt7j0mC"},"source":["# Label Map 생성\n","- text 에디터에서 직접 작성\n","- File iO를 이용해 코드 상에서 파일 작성"]},{"cell_type":"code","metadata":{"id":"kCCMryeTj0mC","executionInfo":{"status":"ok","timestamp":1620994293346,"user_tz":-540,"elapsed":2721956,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["labels = [\n","    {'name':'one', 'id':1},\n","    {'name':'two', 'id':2},\n","    {'name':'three', 'id':3},\n","    {'name':'four', 'id':4},\n","    {'name':'five', 'id':5},\n","]\n","\n","with open(LABEL_MAP_FILE_PATH, 'wt') as fw:\n","    for label in labels:\n","        fw.write('item:{\\n')\n","        fw.write('\\tname:\"{}\"\\n'.format(label['name']))\n","        fw.write(\"\\tid:{}\\n\".format(label['id']))\n","        fw.write(\"}\\n\")"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"2n6Tk6vMj0mC","executionInfo":{"status":"ok","timestamp":1620994293348,"user_tz":-540,"elapsed":2721955,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt8w_6R6j0mD","executionInfo":{"status":"ok","timestamp":1620994293350,"user_tz":-540,"elapsed":2721955,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZuVligHIj0mD"},"source":["# TFRecord 생성\n","- scripts/generate_tfrecord.py\n","    - command line argument\n","        - -x, --xml_dir: annotation 파일이 있는 경로\n","        - -l, --labels_path: Label map의 경로(파일명 포함)\n","        - -o, --output_path: 생성된 tfrecord 파일을 저장할 디렉토리\n","        - -i, --image_dir: 이미지 데이터가 있는 디렉토리 경로(annotation과 동일한 위치에 있으면 생략 가능: -x)"]},{"cell_type":"code","metadata":{"id":"CBSNIneJj0mD","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1620994293351,"user_tz":-540,"elapsed":2721945,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"adacdd6c-671f-47b1-b730-a57a0bcb5db9"},"source":["# train set 생성\n","f'!python  ./{SCRIPT_PATH}/generate_tfrecord.py -x {os.path.join(IMAGE_PATH, \"train\")} -l {LABEL_MAP_FILE_PATH} -o {os.path.join(TF_RECORD_PATH, \"train.tfr\")}'"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!python  ./scripts/generate_tfrecord.py -x workspace/images/train -l workspace/labelmap/label_map.pbtxt -o workspace/tfrecord/train.tfr'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"66V8Azrvj0mD","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1620994293352,"user_tz":-540,"elapsed":2721929,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"e61fa027-0adf-49c8-ad2f-6c098879d819"},"source":["# test set\n","f'!python  ./{SCRIPT_PATH}/generate_tfrecord.py -x {os.path.join(IMAGE_PATH, \"test\")} -l {LABEL_MAP_FILE_PATH} -o {os.path.join(TF_RECORD_PATH, \"test.tfr\")}'"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!python  ./scripts/generate_tfrecord.py -x workspace/images/test -l workspace/labelmap/label_map.pbtxt -o workspace/tfrecord/test.tfr'"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y93Y6yOasIIl","executionInfo":{"status":"ok","timestamp":1620994297995,"user_tz":-540,"elapsed":2726557,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"34497d0b-576a-4ff7-facd-dcb559e405a4"},"source":["!python  ./scripts/generate_tfrecord.py -x workspace/images/train -l workspace/labelmap/label_map.pbtxt -o workspace/tfrecord/train.tfr"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecord file: workspace/tfrecord/train.tfr\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6g-pvsssIQI","executionInfo":{"status":"ok","timestamp":1620994302187,"user_tz":-540,"elapsed":2730735,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"9f29080e-ef29-46b1-de69-abc1fbbbd828"},"source":["!python  ./scripts/generate_tfrecord.py -x workspace/images/test -l workspace/labelmap/label_map.pbtxt -o workspace/tfrecord/test.tfr"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Successfully created the TFRecord file: workspace/tfrecord/test.tfr\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ka753XFaj0mD"},"source":["# Pretrained Model Download\n","- Tensorflow object detection API는 MS COCO 2017 dataset으로 미리 학습시킨 다양한 Object Detection 모델을 제공한다.\n","- tf2 detection Model Zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n","- SSD MobileNet V2 FPNLite 320x320 다운로드\n","    - 성능은 떨어지지만 학습속도가 빠르다."]},{"cell_type":"code","metadata":{"id":"2PyGxtE4j0mE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620994302626,"user_tz":-540,"elapsed":2731158,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"4d85a49f-e25d-4f45-bf61-50d124eefd89"},"source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"],"execution_count":28,"outputs":[{"output_type":"stream","text":["--2021-05-14 12:11:41--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.206.128, 2a00:1450:400c:c09::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.206.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20515344 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.1’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.56M  39.2MB/s    in 0.5s    \n","\n","2021-05-14 12:11:41 (39.2 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.1’ saved [20515344/20515344]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SrF6AYwzj0mE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620994306661,"user_tz":-540,"elapsed":2735178,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"c0c35e3b-fd50-4ce7-d5ac-0f9367d49363"},"source":["!tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  -C workspace/pre_trained_model/"],"execution_count":29,"outputs":[{"output_type":"stream","text":["ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JHUEdHvEj0mE"},"source":["# Pipeline.config 설정 변경"]},{"cell_type":"markdown","metadata":{"id":"eOAr5zegj0mE"},"source":["## pipeline.config  파일 개요\n","- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n","- 구조\n","    - https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md\n","    - **model**\n","        - 사용하는 모델에 대한 설정\n","        - class 개수\n","        - 입력이미지 size\n","        - anchor 설정\n","    - **train_config**\n","        - Train(학습)관련 설정\n","        - batch_size\n","            - 사용하는 GPU의 메모리 크기에 맞게 조절한다.\n","        - image augmentation관련 설정 등\n","        - optimizer관련 설정\n","        - 학습에 사용할 weight 파일의 경로\n","    - **train_input_reader**\n","        - labelmap 파일 경로\n","        - train tfrecord 파일 경로\n","    - **eval_config**\n","        - evaluation(평가)을 위해 사용하는 metric 설정\n","    - **eval_input_reader**\n","        - labelmap 파일 경로\n","        - evaluation tfrecord 파일 경로\n","        "]},{"cell_type":"markdown","metadata":{"id":"pbH47jhaj0mF"},"source":["## Pretrain model의 pipeline.config 파일 카피\n","- pretrained 모델의 압축을 풀면 pipeline.config 파일이 있다.\n","- workspace\\model 로 copy 한다."]},{"cell_type":"code","metadata":{"id":"zMeSGfLpj0mF","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1620994306662,"user_tz":-540,"elapsed":2735164,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"fb9f8c96-49e5-436b-811e-b2d6fd9120df"},"source":["f\"!cp {os.path.join(PRE_TRAINED_MODEL_PATH, 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8', 'pipeline.config')}  {PIPELINE_CONFIG_PATH}\""],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!cp workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config  workspace/model/pipeline.config'"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"NNd0f_GCj0mF","executionInfo":{"status":"ok","timestamp":1620994307698,"user_tz":-540,"elapsed":2736186,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["!cp workspace/pre_trained_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config  workspace/model/pipeline.config"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkT4zkIK5LHs","executionInfo":{"status":"ok","timestamp":1620994307700,"user_tz":-540,"elapsed":2736182,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wgIDpIGoj0mF"},"source":["## pipeline.config 설정 변경\n","- pipeline.config 내용 변경은 파일을 **직접 변경**할 수도 있고 **코드상에서 변경**할 수도 있다.\n","\n","### 필수 변경사항\n","-  class개수 변경\n","-  train 배치 사이즈 변경 - gpu 메모리 사양에 맞게 변경한다.\n","-  pretrained model 경로 설정\n","-  pretrained model이 어떤 종류의 모델인지 설정\n","-  train 관련 변경\n","    -  labelmap 파일 경로 설정\n","    -  train 용 tfrecord 파일 경로 지정\n","-  evaluation 관련 변경\n","    -  labelmap 파일 경로 설정\n","    -  evaluation 용 tfrecord 파일 경로 지정"]},{"cell_type":"code","metadata":{"id":"8cQM1iCxj0mF","executionInfo":{"status":"ok","timestamp":1620994309795,"user_tz":-540,"elapsed":2738270,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQls0KPaj0mG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620994309796,"user_tz":-540,"elapsed":2738257,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}},"outputId":"044e4b8b-0519-464a-eed3-14a026c0a6c8"},"source":["# pipeline.config 파일을 조회 출력\n","config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)  #pipeline.config 파일경로를 주면 딕셔너리로 읽어온다\n","print(type(config))\n","config"],"execution_count":33,"outputs":[{"output_type":"stream","text":["<class 'dict'>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false,\n"," 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 320\n","       width: 320\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," },\n"," 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }}"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"K1HpYPP0j0mG","executionInfo":{"status":"ok","timestamp":1620994309798,"user_tz":-540,"elapsed":2738244,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# 특정 설정들을 변경(수정)\n","# pipeline.config 템플릿(설정 값이 없는 빈 템플릿) 생성\n","pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"9S-QxsPdj0mG","executionInfo":{"status":"ok","timestamp":1620994309801,"user_tz":-540,"elapsed":2738236,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# 기존 pipeline.config의 설정을 읽어서 template에 덮어쓴다\n","with tf.io.gfile.GFile(PIPELINE_CONFIG_PATH, 'r') as fr:\n","    proto_str = fr.read()\n","    text_format.Merge(proto_str, pipeline_config)  #읽어온 str이 pipeline_config에 추가"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"74axDcaIj0mG","executionInfo":{"status":"ok","timestamp":1620994309803,"user_tz":-540,"elapsed":2738231,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# 항목별로 수정\n","# class 개수 변경\n","pipeline_config.model.ssd.num_classes = 5\n","\n","# batch size 변경\n","pipeline_config.train_config.batch_size = 16\n","\n","# pretrained model에 넣어줄 weight(가중치) 파일 경로 설정\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(PRE_TRAINED_MODEL_PATH,\"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\", \"checkpoint\", 'ckpt-0')\n","# 어떤 작업을 위한 가중치인지 설정\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","\n","# train 입력 데이터 관련 설정\n","# labelmap 파일 경로 설정\n","pipeline_config.train_input_reader.label_map_path = LABEL_MAP_FILE_PATH\n","# train용 tfrecord 파일 경로\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(TF_RECORD_PATH, 'train.tfr')]\n","\n","# evaluation 설정\n","pipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP_FILE_PATH\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(TF_RECORD_PATH, 'test.tfr')]\n"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CLMAgaoj0mG","executionInfo":{"status":"ok","timestamp":1620994309804,"user_tz":-540,"elapsed":2738224,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":["# 변경사항을 파일에 저장\n","config_txt = text_format.MessageToString(pipeline_config)  #pipeline_config의 설정들을 문자열(string)으로 변환\n","# 출력\n","with open(PIPELINE_CONFIG_PATH, 'w') as fw:\n","    fw.write(config_txt)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8AxTH0NEYc8","executionInfo":{"status":"ok","timestamp":1620994309804,"user_tz":-540,"elapsed":2738220,"user":{"displayName":"녹색사람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3GPueW40grKUNtTRE9Xhn5BFfwCwxf5zoTPkq=s64","userId":"18371923427764009955"}}},"source":[""],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f5WklfdRj0mG"},"source":["# Model 학습\n","- 다음 명령어를 실행한다.\n","- 시간이 오래 걸리므로 terminal에서 실행한다.\n","```\n","python models/research/object_detection/model_main_tf2.py --model_dir=workspace/model/checkpoint --pipeline_config_path=workspace/model/pipeline.config --num_train_steps=3000\n","```\n","\n","## 옵션\n","- model_dir: 학습한 모델의 checkpoint 파일을 저장할 경로. (1000 step당 저장한다.)\n","- pipeline_config_path: pipeline.config 파일 경로\n","- num_train_steps: 학습할 step 수"]},{"cell_type":"code","metadata":{"id":"GD5C6Trcj0mI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5233927-719d-44ca-eccc-5a2933be9c2f"},"source":["# 2만번 돌려보기\n","!python models/research/object_detection/model_main_tf2.py --model_dir=workspace/model/checkpoint --pipeline_config_path=workspace/model/pipeline.config --num_train_steps=20000"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-05-14 12:38:15.611541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:38:19.630063: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-05-14 12:38:19.631073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-05-14 12:38:19.652913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:19.653716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n","coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n","2021-05-14 12:38:19.653761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:38:19.657705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-05-14 12:38:19.657789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-05-14 12:38:19.660522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-05-14 12:38:19.660956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-05-14 12:38:19.667107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-05-14 12:38:19.667787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-05-14 12:38:19.668051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-05-14 12:38:19.668189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:19.668976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:19.669762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-05-14 12:38:19.670264: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-05-14 12:38:19.670399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:19.671164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n","coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n","2021-05-14 12:38:19.671202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:38:19.671246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-05-14 12:38:19.671297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-05-14 12:38:19.671350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-05-14 12:38:19.671398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-05-14 12:38:19.671441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-05-14 12:38:19.671490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-05-14 12:38:19.671540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-05-14 12:38:19.671645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:19.672465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:19.673222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-05-14 12:38:19.673276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-05-14 12:38:20.169240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-05-14 12:38:20.169303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-05-14 12:38:20.169326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-05-14 12:38:20.169576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:20.170386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:20.171193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-14 12:38:20.172009: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-05-14 12:38:20.172068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10637 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0514 12:38:20.174557 139794521282432 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 20000\n","I0514 12:38:20.181290 139794521282432 config_util.py:552] Maybe overwriting train_steps: 20000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0514 12:38:20.181480 139794521282432 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0514 12:38:20.303150 139794521282432 deprecation.py:339] From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['workspace/tfrecord/train.tfr']\n","I0514 12:38:20.325498 139794521282432 dataset_builder.py:163] Reading unweighted datasets: ['workspace/tfrecord/train.tfr']\n","INFO:tensorflow:Reading record datasets for input file: ['workspace/tfrecord/train.tfr']\n","I0514 12:38:20.326016 139794521282432 dataset_builder.py:80] Reading record datasets for input file: ['workspace/tfrecord/train.tfr']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0514 12:38:20.326193 139794521282432 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0514 12:38:20.326320 139794521282432 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0514 12:38:20.337898 139794521282432 deprecation.py:339] From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0514 12:38:20.369278 139794521282432 deprecation.py:339] From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0514 12:38:28.470199 139794521282432 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0514 12:38:31.984605 139794521282432 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0514 12:38:34.001832 139794521282432 deprecation.py:339] From /content/drive/MyDrive/object_detection/object_detection_workspace/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-05-14 12:38:38.069177: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-05-14 12:38:38.078178: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-05-14 12:39:07.505808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-05-14 12:39:09.486616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-05-14 12:39:09.509623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n","W0514 12:39:38.121050 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._groundtruth_lists\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor\n","W0514 12:39:38.121490 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","W0514 12:39:38.121641 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\n","W0514 12:39:38.121769 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","W0514 12:39:38.121921 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","W0514 12:39:38.122045 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\n","W0514 12:39:38.122177 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\n","W0514 12:39:38.122284 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\n","W0514 12:39:38.122389 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\n","W0514 12:39:38.122502 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","W0514 12:39:38.122624 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\n","W0514 12:39:38.122759 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\n","W0514 12:39:38.122879 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\n","W0514 12:39:38.122997 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\n","W0514 12:39:38.123136 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\n","W0514 12:39:38.123250 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\n","W0514 12:39:38.123356 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\n","W0514 12:39:38.123469 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower\n","W0514 12:39:38.123581 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\n","W0514 12:39:38.123717 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\n","W0514 12:39:38.123890 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\n","W0514 12:39:38.124023 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\n","W0514 12:39:38.124167 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\n","W0514 12:39:38.124284 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\n","W0514 12:39:38.124425 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\n","W0514 12:39:38.124557 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\n","W0514 12:39:38.124678 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\n","W0514 12:39:38.124786 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\n","W0514 12:39:38.124893 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\n","W0514 12:39:38.125020 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\n","W0514 12:39:38.125138 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\n","W0514 12:39:38.125247 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.0\n","W0514 12:39:38.125353 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.1\n","W0514 12:39:38.125473 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.2\n","W0514 12:39:38.125614 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.3\n","W0514 12:39:38.125758 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\n","W0514 12:39:38.125922 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\n","W0514 12:39:38.126060 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\n","W0514 12:39:38.126253 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.3\n","W0514 12:39:38.126364 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.3\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n","W0514 12:39:38.126546 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n","W0514 12:39:38.126688 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n","W0514 12:39:38.126820 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\n","W0514 12:39:38.126947 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\n","W0514 12:39:38.127067 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\n","W0514 12:39:38.127189 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\n","W0514 12:39:38.127296 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\n","W0514 12:39:38.127403 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\n","W0514 12:39:38.127538 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\n","W0514 12:39:38.127647 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10\n","W0514 12:39:38.127754 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.11\n","W0514 12:39:38.127904 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\n","W0514 12:39:38.128037 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\n","W0514 12:39:38.128182 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\n","W0514 12:39:38.128325 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\n","W0514 12:39:38.128446 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\n","W0514 12:39:38.128566 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\n","W0514 12:39:38.128702 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10\n","W0514 12:39:38.128840 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.11\n","W0514 12:39:38.129025 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\n","W0514 12:39:38.129175 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\n","W0514 12:39:38.129316 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\n","W0514 12:39:38.129441 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\n","W0514 12:39:38.129587 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\n","W0514 12:39:38.180529 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\n","W0514 12:39:38.180710 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10\n","W0514 12:39:38.180873 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.11\n","W0514 12:39:38.181118 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\n","W0514 12:39:38.181284 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\n","W0514 12:39:38.181427 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\n","W0514 12:39:38.181824 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\n","W0514 12:39:38.182066 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\n","W0514 12:39:38.182250 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\n","W0514 12:39:38.182399 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10\n","W0514 12:39:38.182544 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.11\n","W0514 12:39:38.182688 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\n","W0514 12:39:38.182847 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\n","W0514 12:39:38.183002 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\n","W0514 12:39:38.183166 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\n","W0514 12:39:38.183327 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\n","W0514 12:39:38.183470 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\n","W0514 12:39:38.183611 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10\n","W0514 12:39:38.183767 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.11\n","W0514 12:39:38.183908 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\n","W0514 12:39:38.184056 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\n","W0514 12:39:38.184214 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\n","W0514 12:39:38.184392 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\n","W0514 12:39:38.184570 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\n","W0514 12:39:38.184714 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\n","W0514 12:39:38.184874 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10\n","W0514 12:39:38.185032 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.11\n","W0514 12:39:38.185194 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\n","W0514 12:39:38.185340 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\n","W0514 12:39:38.185485 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\n","W0514 12:39:38.185628 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\n","W0514 12:39:38.185783 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\n","W0514 12:39:38.185923 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\n","W0514 12:39:38.186074 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10\n","W0514 12:39:38.186230 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.11\n","W0514 12:39:38.186371 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\n","W0514 12:39:38.186512 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\n","W0514 12:39:38.186649 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\n","W0514 12:39:38.186788 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\n","W0514 12:39:38.186926 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\n","W0514 12:39:38.187072 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\n","W0514 12:39:38.187227 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10\n","W0514 12:39:38.187366 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.11\n","W0514 12:39:38.187506 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\n","W0514 12:39:38.187647 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\n","W0514 12:39:38.187786 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\n","W0514 12:39:38.187945 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\n","W0514 12:39:38.188110 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\n","W0514 12:39:38.188314 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\n","W0514 12:39:38.188451 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10\n","W0514 12:39:38.188638 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.11\n","W0514 12:39:38.188795 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\n","W0514 12:39:38.188949 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\n","W0514 12:39:38.189101 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\n","W0514 12:39:38.189258 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\n","W0514 12:39:38.189396 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\n","W0514 12:39:38.189537 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\n","W0514 12:39:38.189678 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10\n","W0514 12:39:38.189816 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.11\n","W0514 12:39:38.189954 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.11\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.0.depthwise_kernel\n","W0514 12:39:38.190119 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.0.pointwise_kernel\n","W0514 12:39:38.190272 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.1.depthwise_kernel\n","W0514 12:39:38.190408 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.1.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.1.pointwise_kernel\n","W0514 12:39:38.190561 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.1.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.2.depthwise_kernel\n","W0514 12:39:38.190703 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.2.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.2.pointwise_kernel\n","W0514 12:39:38.190841 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.2.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.3.depthwise_kernel\n","W0514 12:39:38.190986 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.3.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.3.pointwise_kernel\n","W0514 12:39:38.191138 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.PredictionTower.3.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n","W0514 12:39:38.191284 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.depthwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n","W0514 12:39:38.191439 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.pointwise_kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n","W0514 12:39:38.191582 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\n","W0514 12:39:38.191725 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n","W0514 12:39:38.191867 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n","W0514 12:39:38.192046 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\n","W0514 12:39:38.192197 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\n","W0514 12:39:38.192335 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\n","W0514 12:39:38.192517 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n","W0514 12:39:38.192665 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n","W0514 12:39:38.192839 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\n","W0514 12:39:38.192986 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\n","W0514 12:39:38.193143 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\n","W0514 12:39:38.193287 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n","W0514 12:39:38.193427 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n","W0514 12:39:38.193566 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\n","W0514 12:39:38.193722 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\n","W0514 12:39:38.193883 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.axis\n","W0514 12:39:38.194056 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.gamma\n","W0514 12:39:38.194235 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.beta\n","W0514 12:39:38.194389 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_mean\n","W0514 12:39:38.194552 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_variance\n","W0514 12:39:38.194725 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\n","W0514 12:39:38.194863 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n","W0514 12:39:38.195049 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n","W0514 12:39:38.195214 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\n","W0514 12:39:38.195363 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\n","W0514 12:39:38.195539 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\n","W0514 12:39:38.195679 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n","W0514 12:39:38.195817 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n","W0514 12:39:38.195968 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\n","W0514 12:39:38.196111 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\n","W0514 12:39:38.196267 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\n","W0514 12:39:38.196423 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n","W0514 12:39:38.196582 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n","W0514 12:39:38.196727 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\n","W0514 12:39:38.196897 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\n","W0514 12:39:38.197047 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.axis\n","W0514 12:39:38.197208 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.gamma\n","W0514 12:39:38.197351 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.beta\n","W0514 12:39:38.197490 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_mean\n","W0514 12:39:38.197629 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_variance\n","W0514 12:39:38.197769 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\n","W0514 12:39:38.197909 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n","W0514 12:39:38.198085 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n","W0514 12:39:38.198277 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\n","W0514 12:39:38.198417 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\n","W0514 12:39:38.198590 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\n","W0514 12:39:38.198733 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n","W0514 12:39:38.198875 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n","W0514 12:39:38.199056 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\n","W0514 12:39:38.199213 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\n","W0514 12:39:38.199354 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\n","W0514 12:39:38.199497 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n","W0514 12:39:38.199653 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n","W0514 12:39:38.199793 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\n","W0514 12:39:38.199931 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\n","W0514 12:39:38.200081 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.axis\n","W0514 12:39:38.200306 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.gamma\n","W0514 12:39:38.200527 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.beta\n","W0514 12:39:38.200692 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_mean\n","W0514 12:39:38.200863 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_variance\n","W0514 12:39:38.201017 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\n","W0514 12:39:38.201170 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n","W0514 12:39:38.201330 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n","W0514 12:39:38.201473 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\n","W0514 12:39:38.201629 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\n","W0514 12:39:38.201799 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\n","W0514 12:39:38.201937 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n","W0514 12:39:38.202086 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n","W0514 12:39:38.202272 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\n","W0514 12:39:38.202432 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\n","W0514 12:39:38.202624 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\n","W0514 12:39:38.202782 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n","W0514 12:39:38.202936 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n","W0514 12:39:38.203099 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\n","W0514 12:39:38.203265 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\n","W0514 12:39:38.203405 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.axis\n","W0514 12:39:38.203596 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.gamma\n","W0514 12:39:38.203755 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.beta\n","W0514 12:39:38.203916 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_mean\n","W0514 12:39:38.204069 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_variance\n","W0514 12:39:38.204251 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\n","W0514 12:39:38.204392 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n","W0514 12:39:38.204580 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n","W0514 12:39:38.204740 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\n","W0514 12:39:38.204913 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\n","W0514 12:39:38.205076 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\n","W0514 12:39:38.205252 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n","W0514 12:39:38.205440 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n","W0514 12:39:38.205589 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\n","W0514 12:39:38.205791 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\n","W0514 12:39:38.205929 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\n","W0514 12:39:38.206082 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n","W0514 12:39:38.206235 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n","W0514 12:39:38.206373 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\n","W0514 12:39:38.206595 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\n","W0514 12:39:38.206745 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.axis\n","W0514 12:39:38.206933 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.axis\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.gamma\n","W0514 12:39:38.207084 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.beta\n","W0514 12:39:38.207237 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_mean\n","W0514 12:39:38.207392 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_mean\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_variance\n","W0514 12:39:38.207545 139794521282432 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_variance\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","W0514 12:39:38.207710 139794521282432 util.py:169] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0514 12:39:53.871428 139793769711360 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 1100 per-step time 1.085s loss=0.254\n","I0514 12:41:32.959904 139794521282432 model_lib_v2.py:683] Step 1100 per-step time 1.085s loss=0.254\n","INFO:tensorflow:Step 1200 per-step time 0.570s loss=0.233\n","I0514 12:42:29.971388 139794521282432 model_lib_v2.py:683] Step 1200 per-step time 0.570s loss=0.233\n","INFO:tensorflow:Step 1300 per-step time 0.566s loss=0.247\n","I0514 12:43:26.580235 139794521282432 model_lib_v2.py:683] Step 1300 per-step time 0.566s loss=0.247\n","INFO:tensorflow:Step 1400 per-step time 0.566s loss=0.263\n","I0514 12:44:23.214352 139794521282432 model_lib_v2.py:683] Step 1400 per-step time 0.566s loss=0.263\n","INFO:tensorflow:Step 1500 per-step time 0.570s loss=0.234\n","I0514 12:45:20.220658 139794521282432 model_lib_v2.py:683] Step 1500 per-step time 0.570s loss=0.234\n","INFO:tensorflow:Step 1600 per-step time 0.574s loss=0.266\n","I0514 12:46:17.620380 139794521282432 model_lib_v2.py:683] Step 1600 per-step time 0.574s loss=0.266\n","INFO:tensorflow:Step 1700 per-step time 0.566s loss=0.212\n","I0514 12:47:14.195428 139794521282432 model_lib_v2.py:683] Step 1700 per-step time 0.566s loss=0.212\n","INFO:tensorflow:Step 1800 per-step time 0.566s loss=0.239\n","I0514 12:48:10.750999 139794521282432 model_lib_v2.py:683] Step 1800 per-step time 0.566s loss=0.239\n","INFO:tensorflow:Step 1900 per-step time 0.568s loss=0.212\n","I0514 12:49:07.527342 139794521282432 model_lib_v2.py:683] Step 1900 per-step time 0.568s loss=0.212\n","INFO:tensorflow:Step 2000 per-step time 0.573s loss=0.204\n","I0514 12:50:04.838657 139794521282432 model_lib_v2.py:683] Step 2000 per-step time 0.573s loss=0.204\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.963604 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.965749 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.969608 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.971046 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.974854 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.976877 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.979410 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.980491 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.983015 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0514 12:50:04.984124 139794521282432 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Step 2100 per-step time 0.579s loss=0.198\n","I0514 12:51:02.786401 139794521282432 model_lib_v2.py:683] Step 2100 per-step time 0.579s loss=0.198\n","INFO:tensorflow:Step 2200 per-step time 0.575s loss=0.306\n","I0514 12:52:00.303544 139794521282432 model_lib_v2.py:683] Step 2200 per-step time 0.575s loss=0.306\n","INFO:tensorflow:Step 2300 per-step time 0.572s loss=0.215\n","I0514 12:52:57.469959 139794521282432 model_lib_v2.py:683] Step 2300 per-step time 0.572s loss=0.215\n","INFO:tensorflow:Step 2400 per-step time 0.569s loss=0.191\n","I0514 12:53:54.376457 139794521282432 model_lib_v2.py:683] Step 2400 per-step time 0.569s loss=0.191\n","INFO:tensorflow:Step 2500 per-step time 0.567s loss=0.191\n","I0514 12:54:51.106314 139794521282432 model_lib_v2.py:683] Step 2500 per-step time 0.567s loss=0.191\n","INFO:tensorflow:Step 2600 per-step time 0.573s loss=0.193\n","I0514 12:55:48.419477 139794521282432 model_lib_v2.py:683] Step 2600 per-step time 0.573s loss=0.193\n","INFO:tensorflow:Step 2700 per-step time 0.575s loss=0.194\n","I0514 12:56:45.953966 139794521282432 model_lib_v2.py:683] Step 2700 per-step time 0.575s loss=0.194\n","INFO:tensorflow:Step 2800 per-step time 0.572s loss=0.197\n","I0514 12:57:43.153020 139794521282432 model_lib_v2.py:683] Step 2800 per-step time 0.572s loss=0.197\n","INFO:tensorflow:Step 2900 per-step time 0.568s loss=0.207\n","I0514 12:58:39.911194 139794521282432 model_lib_v2.py:683] Step 2900 per-step time 0.568s loss=0.207\n","INFO:tensorflow:Step 3000 per-step time 0.574s loss=0.178\n","I0514 12:59:37.323338 139794521282432 model_lib_v2.py:683] Step 3000 per-step time 0.574s loss=0.178\n","INFO:tensorflow:Step 3100 per-step time 0.575s loss=0.226\n","I0514 13:00:34.804208 139794521282432 model_lib_v2.py:683] Step 3100 per-step time 0.575s loss=0.226\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J2CzziGOj0mI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cCi-bifxj0mI"},"source":["# 학습한 모델 추출(export)\n","- `models/research/object_detection/exporter_main_v2.py` 사용\n","- 옵션\n","    - `exporter_main_v2.py --helpshort || exporter_main_v2.py --helpfull`\n","    - input_type : input node type\n","        - image_tensor, encoded_image_string_tensor\n","    - train_checkpoint: 학습된 checkpoint 파일이 저장된 경로(folder/directory)\n","    - pipeline_config_path: pipeline.config 파일의 경로 (파일명 포함)\n","    - output_directory: export된 모델을 저장할 경로.\n","- 추출된 디렉토리 구조\n","```bash\n","output_dir\n","├─ checkpoint/\n","├─ save_model/\n","└─ pipeline.config\n","```\n","    - checkpoint: custom data 학습한 checkpoint 파일들을 이 디렉토리로 복사한다.\n","    - save_model: pipeline.config 설정에 맞춰 생성된 model\n","    - pipeline.config: pipeline.config 설정파일"]},{"cell_type":"code","metadata":{"id":"SSa5TlMZj0mJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSF2zYXZj0mK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EI6INiy4j0mK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_3MCUc5j0mL"},"source":["# Inference(추론)"]},{"cell_type":"markdown","metadata":{"id":"YKhMsyohj0mL"},"source":["### 사용 함수,메소드\n","-  ### tf.convert_to_tensor(array_like, dtype)\n","    - array_like 를 Tensoflow Tensor 객체로 변환\n","    - `tf.convert_to_tensor([[1,2],[3,4]])`\n","- ### detection_model.preprocess(image 4차원 ndarray)\n","    - 전달받은 이미지를 model의 input shape에 맞게 resizing 한다.\n","    - 반환값: (resize된 image Tensor, 이미지의 shape) 을 tuple로 반환\n","- ### detection_model.predict(image tensor, image_shape tensor)\n","    - 추론/detection 메소드\n","    - 이미지와 image shape을 받아서 detection한 결과를 딕셔너리로 반환한다.\n","    - **반환 dictionary key**\n","        - **preprocessed_inputs**:  입력 이미지 Tensor. preprocess()로 처리된 이미지. \n","        - **feature_maps**: List. feature map 들을 반환\n","        - **anchors**: 2D Tensor. normalize 된 anchor box들의 좌표를 반환. 2-D float tensor: \\[num_anchors, 4\\]\n","        - **final_anchors**: 3D Tensor. batch 당 anchors. (anchors에 batch가 포함된 것). \\[batch_size, num_anchors, 4\\]\n","        - **box_encodings**: 3D flost tensor. predict한 box들의 normalize된 좌표. \\[batch_size, num_anchors,box_code_dimension\\]\n","        - **class_predictions_with_background**: 3D Tensor. 클래스 확률을 반환.(logit). \\[batch_size, num_anchors, num_classes+1]\\\n","            - background 확률을 포함해서 num_classes+1개가 된다. (index 0: background)\n","            \n","- ### detection_model.postprocess(prediction_dict, shape)\n","    - predict()가 예측한 결과에서 **Non-Maxinum Suppression**을 실행해서 최종 Detection 결과를 반환한다.\n","        - predict()는 anchor별로 예측결과를 모아서 주고 post-process는 최종 결과를 추출해서 반환.\n","    - **반환 dictionary key**\n","        - **num_detections**: Detect한 개수 (bounding box 개수)\n","        - **detection_boxes**: [batch, max_detections, 4]. 후처리한 detection box\n","        - **detection_scores**: [batch, max_detections]. post-processed detection box들의 detection score들 (detection score는 box안에 물체가 있을 확률값 - confidence score).\n","        - **detection_classes**: [batch, max_detections] tensor with classes for post-processed detection classes.\n","        - **raw_detection_boxes**:[batch, total_detections, 4] Non-Max Suppression 하기 전의 감지된 box들\n","        - **raw_detection_scores**: [batch, total_detections, num_classes_with_background]. raw detection box들의 class별 점수\n","        - **detection_multiclass_scores**: [batch, max_detections, num_classes_with_background] post-processed이후 남은 bounding box 들의 class별 점수. LabelMap의 class에 background가 추가되어 계산된다.\n","        - **detection_anchor_indices**: [batch, max_detections] post-processed 이후 나은 anchor box의 index들."]},{"cell_type":"code","metadata":{"id":"QC_NmNN3j0mN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJWoG80Tj0mN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ddfqcNsj0mO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMuXiknxj0mO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnT_xLR_j0mO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79ZRkMKwj0mO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pqwksrv-j0mP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xeShgt7j0mP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7R5zmWNj0mP"},"source":[""],"execution_count":null,"outputs":[]}]}